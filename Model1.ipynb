{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tOHCvL9HWp8g"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RSwThFQGWs7M"
      },
      "outputs": [],
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eksquZ9WXTAd",
        "outputId": "8ba73bad-0f8e-4342-fe38-b8f372736b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.18MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.77MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2SMcUkaWuHw",
        "outputId": "008e6d6b-506c-41e4-b909-ae229083655f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RkAr1BThWvz0"
      },
      "outputs": [],
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model1, self).__init__()\n",
        "\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.ReLU()\n",
        "        ) # INPUT 28*28 | OUTPUT 26*26 | RF 3\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=8, kernel_size=(3, 3), padding=0),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU()\n",
        "        ) # INPUT 26*26 | OUTPUT 24*24 | RF 5\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=0),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU()\n",
        "        ) # INPUT 24*24 | OUTPUT 22*22 | RF 7\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # INPUT 22*22 | OUTPUT 11*11 | RF 8\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=20, kernel_size=(3, 3), padding=0),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU()\n",
        "        ) # INPUT 11*11 | OUTPUT 9*9 | RF 12\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20, out_channels=16, kernel_size=(3, 3), padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        ) # INPUT 9*9 | OUTPUT 7*7 | RF 16\n",
        "\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(3, 3), padding=0),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.ReLU()\n",
        "        ) # INPUT 7*7 | OUTPUT 5*5 | RF 20\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0)\n",
        "        ) # INPUT 5*5 | OUTPUT 3*3 | RF 24\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(3)\n",
        "        ) # INPUT 3*3 | OUTPUT 1*1 | RF 28\n",
        "\n",
        "        self.dropout = nn.Dropout(0.01) \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.dropout(x)  \n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.dropout(x) \n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piJaCi-iWx4E",
        "outputId": "d41052f2-3d57-4c96-825f-602b6a3ad970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 26, 26]             100\n",
            "       BatchNorm2d-2           [-1, 10, 26, 26]              20\n",
            "              ReLU-3           [-1, 10, 26, 26]               0\n",
            "            Conv2d-4            [-1, 8, 24, 24]             728\n",
            "       BatchNorm2d-5            [-1, 8, 24, 24]              16\n",
            "              ReLU-6            [-1, 8, 24, 24]               0\n",
            "           Dropout-7            [-1, 8, 24, 24]               0\n",
            "            Conv2d-8            [-1, 8, 22, 22]             584\n",
            "       BatchNorm2d-9            [-1, 8, 22, 22]              16\n",
            "             ReLU-10            [-1, 8, 22, 22]               0\n",
            "        MaxPool2d-11            [-1, 8, 11, 11]               0\n",
            "           Conv2d-12             [-1, 20, 9, 9]           1,460\n",
            "      BatchNorm2d-13             [-1, 20, 9, 9]              40\n",
            "             ReLU-14             [-1, 20, 9, 9]               0\n",
            "           Conv2d-15             [-1, 16, 7, 7]           2,896\n",
            "      BatchNorm2d-16             [-1, 16, 7, 7]              32\n",
            "             ReLU-17             [-1, 16, 7, 7]               0\n",
            "          Dropout-18             [-1, 16, 7, 7]               0\n",
            "           Conv2d-19             [-1, 10, 5, 5]           1,450\n",
            "      BatchNorm2d-20             [-1, 10, 5, 5]              20\n",
            "             ReLU-21             [-1, 10, 5, 5]               0\n",
            "           Conv2d-22             [-1, 10, 3, 3]             910\n",
            "        AvgPool2d-23             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 8,272\n",
            "Trainable params: 8,272\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.46\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.49\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Model1().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "py8XcG-SWzTe"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "964ZDZirW088",
        "outputId": "3466a8b2-01ed-445e-ace9-a6ebd0e11baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.0803607851266861 Batch_id=468 Accuracy=91.00: 100%|██████████| 469/469 [00:20<00:00, 22.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0673, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.07429290562868118 Batch_id=468 Accuracy=98.20: 100%|██████████| 469/469 [00:17<00:00, 26.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0509, Accuracy: 9847/10000 (98.47%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.022153906524181366 Batch_id=468 Accuracy=98.51: 100%|██████████| 469/469 [00:16<00:00, 28.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0359, Accuracy: 9894/10000 (98.94%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.03196047991514206 Batch_id=468 Accuracy=98.74: 100%|██████████| 469/469 [00:16<00:00, 28.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0301, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.0514090396463871 Batch_id=468 Accuracy=98.92: 100%|██████████| 469/469 [00:16<00:00, 29.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0373, Accuracy: 9884/10000 (98.84%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.01636817865073681 Batch_id=468 Accuracy=98.98: 100%|██████████| 469/469 [00:16<00:00, 27.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0277, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.07352645695209503 Batch_id=468 Accuracy=98.99: 100%|██████████| 469/469 [00:17<00:00, 27.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0221, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.007313742768019438 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:16<00:00, 28.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0250, Accuracy: 9927/10000 (99.27%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.025066301226615906 Batch_id=468 Accuracy=99.10: 100%|██████████| 469/469 [00:16<00:00, 27.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0229, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.008187985047698021 Batch_id=468 Accuracy=99.19: 100%|██████████| 469/469 [00:16<00:00, 27.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0241, Accuracy: 9930/10000 (99.30%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.0016372008249163628 Batch_id=468 Accuracy=99.27: 100%|██████████| 469/469 [00:16<00:00, 28.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0220, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.029993591830134392 Batch_id=468 Accuracy=99.31: 100%|██████████| 469/469 [00:16<00:00, 28.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0212, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.026637496426701546 Batch_id=468 Accuracy=99.28: 100%|██████████| 469/469 [00:16<00:00, 28.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0218, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.006130168214440346 Batch_id=468 Accuracy=99.33: 100%|██████████| 469/469 [00:17<00:00, 27.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0266, Accuracy: 9920/10000 (99.20%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.001742902328260243 Batch_id=468 Accuracy=99.33: 100%|██████████| 469/469 [00:16<00:00, 28.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0232, Accuracy: 9929/10000 (99.29%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model =  Model1().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 15\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn67J4mCZufk"
      },
      "source": [
        "**Target:**\n",
        "\n",
        "Total parameter count should be within 8000\n",
        "\n",
        "Epochs 15 or less\n",
        "\n",
        "Reach test accuracy greater than or equal to 99.40 in continous epoch\n",
        "\n",
        "**Results:**\n",
        "\n",
        "Parameters: 8,272\n",
        "\n",
        "Best Training Accuracy: 99.33\n",
        "\n",
        "Best Test Accuracy: 99.38\n",
        "\n",
        "**Analysis:**\n",
        "\n",
        "Model has been made lighter\n",
        "\n",
        "Model is not too overfitting\n",
        "\n",
        "Required accuracy has not been reached\n",
        "\n",
        "**What can be done:**\n",
        "\n",
        "Introduce image augmentation\n",
        "\n",
        "Increase the dropout rate"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
